# -*- coding: utf-8 -*-
"""Ocean_Poem_hf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CA45YQVfwVEIIO730qZmjRGzQ47yLZNu
"""

!pip install -q transformers accelerate sentencepiece huggingface-hub

import torch
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("Device:", torch.cuda.get_device_name(0))
else:
    print("Running on CPU")

from transformers import pipeline
device = 0 if torch.cuda.is_available() else -1

model_name = "google/flan-t5-small"
pipe = pipeline("text2text-generation", model=model_name, tokenizer=model_name, device=device)

print("Model loaded âœ…")

prompt = "Write a small poem about the ocean"
resp = pipe(prompt, max_new_tokens=120)

print("Prompt:", prompt)
print("\nGenerated Poem:\n")
print(resp[0].get("generated_text", resp[0].get("text", "")))