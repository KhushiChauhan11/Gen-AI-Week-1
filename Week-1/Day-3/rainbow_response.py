# -*- coding: utf-8 -*-
"""Rainbow_Response.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HohNwuKrQdPsBH_KI3c2zaVTGppqImzm
"""

!pip install -q transformers accelerate sentencepiece huggingface-hub

import torch
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("Device name:", torch.cuda.get_device_name(0))
else:
    print("Running on CPU")

from transformers import pipeline


model_name = "google/flan-t5-small"


device = 0

pipe = pipeline("text2text-generation", model=model_name, tokenizer=model_name, device=device)
print("Model loaded successfully âœ…")

prompt = "Explain how rainbows are formed"
resp = pipe(prompt, max_new_tokens=200)

print("User Prompt:", prompt)
print("\nModel Response:\n", resp[0]["generated_text"])