# -*- coding: utf-8 -*-
"""Retrieval_QA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XXyOFOXv1nySMG6AlN2EldoJGtYLRePF
"""

!pip install -q langchain faiss-cpu transformers sentence-transformers

docs = [
    """
    Company Policy Document:

    1. Customers can request a refund within 30 days of purchase if they are not satisfied with the product.
    2. Refunds will be processed back to the original payment method within 7-10 business days.
    3. No refunds are available for digital products once downloaded.
    4. For defective or damaged products, customers can request a replacement or full refund.
    5. Customer service is available via email and phone support during business hours.
    """
]

!pip install -q langchain faiss-cpu sentence-transformers transformers

!pip install -q langchain-community

!pip install requests==2.32.4

from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings

# Sample company policy
docs = [
    """
    Company Policy Document:

    1. Customers can request a refund within 30 days of purchase if they are not satisfied with the product.
    2. Refunds will be processed back to the original payment method within 7-10 business days.
    3. No refunds are available for digital products once downloaded.
    4. For defective or damaged products, customers can request a replacement or full refund.
    5. Customer service is available via email and phone support during business hours.
    """
]

# --- Split documents ---
splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)
chunks = splitter.create_documents(docs)

# --- Embeddings ---
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# --- Vectorstore (FAISS) ---
vectorstore = FAISS.from_documents(chunks, embeddings)

# --- Load model ---
from transformers import pipeline
from langchain_community.llms import HuggingFacePipeline

qa_model = pipeline("text2text-generation", model="google/flan-t5-small", device=0)
llm = HuggingFacePipeline(pipeline=qa_model)

# --- RetrievalQA pipeline ---
from langchain.chains import RetrievalQA
qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), chain_type="stuff")

# --- Ask question ---
query = "What is the refund policy?"
result = qa.run(query)

print("Q:", query)
print("A:", result)